[package]
name = "wordchipper"
description = "HPC Rust LLM Tokenizer Library"
keywords = ["ai", "gpt", "bpe", "tokenizer"]
authors.workspace = true
license.workspace = true
repository.workspace = true

version.workspace = true

edition.workspace = true
rust-version.workspace = true


[package.metadata.docs.rs]
all-features = true


[lints]
workspace = true


[features]
default = [
    "ahash",
    "client",
    "rayon",
]

## The base set of features needed to load and run pre-trained encoders and decoders.
client = [
    "download",
    "std",
]

## The download feature enables downloading vocabularies from the internet.
download = [
    "dep:wordchipper-disk-cache",
    "std",
]

## The training feature enables the training code.
training = [
    "compact_str",
    "dary_heap",
    "std",
]


## The "std" feature enables the use of the `std` library;
## and the "`no_std`" feature enables deps needed when "std" is not enabled.
## (Negative feature deps are not stable yet.)
##
## Note: I am unsure if this is complete. It is tested CI, but I'm unsure
## if I've fully covered it; and I haven't worked out a ``no_std`` deploy test yet.
std = [
    "thiserror/std",
    "dep:base64",
    "dep:strum",
    "dep:strum_macros",
    "aho-corasick/std",
    "fancy-regex/default",
    "log/std",
    "num-traits/std",
    "regex/default",
]
## See [std].
no_std = [
    "hashbrown/alloc"
]

## This swaps all HashMap/HashSet implementations for ``ahash``; which is a performance
## win on many/(most?) modern CPUs.
##
## If both "ahash" and "foldhash" are enabled, then "ahash" will win.
##
## This is done by the ``types::WCHash{*}`` type alias machinery.
## See also the ``hashbrown`` dep used by ``no_std``.
ahash = [
    "dep:ahash",
    "std",
]

## This swaps all HashMap/HashSet implementations for ``ahash``; which is a performance
## win on many/(most?) modern CPUs.
##
## If both "ahash" and "foldhash" are enabled, then "ahash" will win.
##
## This is done by the ``types::WCHash{*}`` type alias machinery.
## See also the ``hashbrown`` dep used by ``no_std``.
foldhash = [
    "dep:foldhash",
    "std",
]


## This enables some parallelism wrappers using the ``rayon`` crate.
##
## TODO: I intend on providing a ``tokio`` based ``async`` parallelism mechanism
## as well, to structure more direct ``regex find > encode span`` pipeline parallelism.
rayon = [
    "dep:rayon",
    "std"
]

## This enables a number of ``tracing`` instrumentation points.
## This is only useful for timing tracing of the library itself.
tracing = [
    "tracing/attributes",
]

## Enable test utilities for downstream users.
testing = []



[dependencies]
# macro packages.
cfg-if = { workspace = true }
document-features = { workspace = true }

thiserror = { workspace = true }
fancy-regex = { workspace = true, features = ["unicode"] }
log = { workspace = true }
aho-corasick = { workspace = true }
logos = { workspace = true }
num-traits = { workspace = true }
regex = { workspace = true, features = ["unicode"] }

# "std" feature deps:
base64 = { workspace = true, optional = true }
strum = { workspace = true, optional = true }
strum_macros = { workspace = true, optional = true }

# "no_std" feature deps:
hashbrown = { workspace = true, optional = true }

ahash = { workspace = true, optional = true }
foldhash = { workspace = true, optional = true }

# "download" feature deps:
wordchipper-disk-cache = { version = "0.7.3", path = "../wordchipper-disk-cache", optional = true }

# "rayon" feature deps:
rayon = { workspace = true, optional = true }

# "training" feature deps:
compact_str = { workspace = true, optional = true }
dary_heap = { workspace = true, optional = true }

# "tracing" feature deps:
tracing = { workspace = true, optional = true }


[dev-dependencies]
compact_str = { workspace = true }
tempdir = { workspace = true }
serial_test = { workspace = true }
